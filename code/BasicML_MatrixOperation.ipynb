{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Scalar, Vector, Matrix, Tensor\n",
        "\n",
        "scalar - 1차원의 숫자\n",
        "vector - 2차원의 숫자\n",
        "matrix - vector들을 모아 만드는 2차원의 숫자 모음\n",
        "tensor - vector, matrix들 모음\n",
        "\n",
        "그림 데이터 같은 경우 3차원으로 된 숫자 데이터들이 순서대로 나열되어있는 데이터\n",
        "그림 데이터를 Tensor로 처리\n"
      ],
      "metadata": {
        "id": "zipah8iNpMbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SIMD 에서 Splat, Join, Add, Mul 함수\n",
        "\n",
        "scalar 단위로 계산하는 것보다 훨씬 더 효율적"
      ],
      "metadata": {
        "id": "8-DaOyFatB7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alias dtype = DType.float32\n",
        "\n",
        "let a = SIMD[dtype].splat(0.5)\n",
        "let b = SIMD[dtype].splat(1.5)\n",
        "# splat은 vector 혹은 tensor의 모든 원소에 같은 값을 집어넣도록 해주는 함수\n",
        "# 새로운 벡터를 만드는데 아주 유용하게 쓰임\n",
        "\n",
        "print(\"SIMD a: \", a)\n",
        "print(\"SIMD b: \", b)\n",
        "print()\n",
        "print(\"SIMD JOIN: \", a.join(b))\n",
        "# join은 두 벡터를 하나의 벡터로 만들어줌 > 차원이 증가\n",
        "print(\"SIMD add: \", a.__add__(b))\n",
        "# add는 두 벡터의 각 요소들을 순서대로 더해줌\n",
        "print(\"SIMD mul: \", a.__mul__(b))\n",
        "# mul은 두 벡터의 각 요소들을 순서대로 곱해줌\n"
      ],
      "metadata": {
        "id": "9wTzqxwwtKLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectorize, Parallelize\n",
        "평균을 빠르게 구하기 위한 벡터화, 병렬화"
      ],
      "metadata": {
        "id": "wt13GY5I0Qg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import rand\n",
        "\n",
        "from algorithm import vectorize, parallelize\n",
        "from sys.info import simdwidthof\n",
        "import benchmark\n",
        "\n",
        "\n",
        "alias dtype = DType.float32\n",
        "alias simd_width = simdwidthof[dtype]()\n",
        "\n",
        "fn row_mean_naive[dtype: DType](t: Tensor[dtype]) -> Tensor[dtype]:\n",
        "  var res = Tensor[dtype](t.dim(0), 1)\n",
        "\n",
        "  for i in range(t.dim(0)):\n",
        "    for j in range(t.dim(1)):\n",
        "      res[i] += t[i, j]\n",
        "    res[i] /=t.dim(1)\n",
        "\n",
        "  return res\n",
        "\n",
        "fn row_mean_updated[dtype: DType](t: Tensor[dtype]) -> Tensor[dtype]:\n",
        "  var res = Tensor[dtype](t.dim(0), 1)\n",
        "  @parameter\n",
        "  fn parallel_reduce_rows(idx:Int) -> None:\n",
        "\n",
        "    @parameter\n",
        "    fn vectorize_reduce_row[simd_width: Int](idx2: Int) -> None:\n",
        "      res[idx1] += t.simd_load[simd_width](idx1* t.dim(0) + idx2).reduce_add()\n",
        "\n",
        "    vectorize[2*simd_width, vectorize_reduce_row](t.dim(1))\n",
        "    res[idx1] /= t.dim(1)\n",
        "  parallelize[parallel_reduce_rows](t.dim(0), t.dim(0))\n",
        "  return res\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fn main():\n",
        "  let t = rand[dtype](1000, 1000000)\n",
        "  var result = Tensor[dtype](t.dim(0),1)\n",
        "  # _ = row_mean_naive(t)\n",
        "\n",
        "  @parameter\n",
        "  fn bech_mean():\n",
        "    _ = row_mean_naive(t)\n",
        "\n",
        "  @parameterfn\n",
        "  fn bech_mean_updated():\n",
        "    _ = row_mean_updated(t)\n",
        "\n",
        "  let report = benchmark.run[bech_mean]()\n",
        "  let report_updated = benchmark.run[bech_mean_updated]()\n",
        "  report.print()\n",
        "  report_updated.print()\n",
        "  print(\"Speed up\", report.mean()/report_updated.mean())\n",
        "\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "aFbjKbkA0X0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Square matrices 만들기, 초기화, 접근, 출력\n",
        "\n",
        "정사각형의 행렬을 만들고, 초기화하고, 요소에 접근하고, 출력하는 효율적인 방식\n"
      ],
      "metadata": {
        "id": "Um92wjHS52H-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from algorithm import vectorize\n",
        "\n",
        "struct SquateMatrix[dtype:DType = DType.float32, dim:Int = 3]():\n",
        "  var mat: Tensor[dtype]\n",
        "\n",
        "  fn __init__(inout self, value: SIMD[dtype, 1] = 6):\n",
        "    self.mat = Tensor[dtype](self.dim, self.dim)\n",
        "\n",
        "    @parameter\n",
        "    fn fill_value[simd_width: Int](idx:Int) -> None:\n",
        "      self.mat.simd_store(idx, self.mat.simd_load[simd_width](idx).splat(value))\n",
        "\n",
        "    vectorize[simd_width, fill_value](self.mat.num_elementes())\n",
        "\n",
        "  fn __getitem__(self, x: Int, y: Int) -> SIMD[dtype, 1]:\n",
        "    return self.mat[x, y]\n",
        "\n",
        "  fn print(self):\n",
        "    print(self.mat)\n",
        "\n",
        "SquateMatrix().print()\n",
        "SquateMatrix(value=7).print()\n",
        "SquateMatrix[DType.float64](value=9).print()\n",
        "SquateMatrix[DType.float64,dim=5](value=9).print()"
      ],
      "metadata": {
        "id": "nFtQ4qTE6C6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Square matrices에 scalar 값 곱하기\n",
        "\n",
        "정사각형의 행렬의 각 요소에 scalar 값 곱하기\n"
      ],
      "metadata": {
        "id": "hcj4liSb7YY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sys.info import simdwidthof\n",
        "from math import mul\n",
        "\n",
        "fn multiply(sm: SquateMatrix, val: SIMD[sm.dtype, 1]) -> Tensor[sm.dtype]:\n",
        "  alias simd_width: Int = simdwidthof[sm.dtype]()\n",
        "  let result_tensor = Tensor[sm.dtype](sm.mat.shape())\n",
        "\n",
        "  @parameter\n",
        "  fn vectorize_multipy[simd_width:Int](idx: Int) -> None:\n",
        "    result_tensor.simd_store[simd_width](idx, mul[sm.dtype, simd_width](sm.mat.simd_load[simd_width](idx), val))\n",
        "\n",
        "  vectorize[simd_width, vectorize_multipy](sm.mat.num_elementes())\n",
        "  return result_tensor\n",
        "\n",
        "\n",
        "let sm = SquateMatrix(6)\n",
        "sm.print()\n",
        "let res = multipy(sm, 100.0)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "sPXm8tny7fep"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}